{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "import json\n",
    "\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "\n",
    "OPENAI_API_KEY=\"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\"\n",
    "LANGSMITH_API_KEY=\"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\"\n",
    "GROQ_API_KEY=\"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\"\n",
    "\n",
    "\n",
    "os.environ['USER_AGENT'] = 'myagent'\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter API key for Langsmith: \")\n",
    "os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter API key for Groq: \")\n",
    "\n",
    "llm = init_chat_model(\"llama3-8b-8192\", model_provider=\"groq\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB restored from 'chroma_backup.json'\n"
     ]
    }
   ],
   "source": [
    "# Initialize Chroma vector_store\n",
    "persist_directory = \"chromadb\"\n",
    "embeddings = OllamaEmbeddings(model=\"llama3\")\n",
    "vector_store = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n",
    "\n",
    "# Load the backup JSON\n",
    "with open(\"json/chroma_backup.json\", \"r\") as f:\n",
    "    backup_data = json.load(f)\n",
    "\n",
    "# Add data back into the vectorstore\n",
    "vector_store.add_texts(\n",
    "    texts=backup_data[\"documents\"],\n",
    "    metadatas=backup_data.get(\"metadatas\", []),\n",
    "    ids=backup_data[\"ids\"]\n",
    ")\n",
    "\n",
    "print(\"ChromaDB restored from 'chroma_backup.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs\n",
    "\n",
    "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
    "async def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = await llm_with_tools.ainvoke(state[\"messages\"])\n",
    "    # MessagesState appends messages to state instead of overwriting\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "# Step 2: Execute the retrieval.\n",
    "tools = ToolNode([retrieve])\n",
    "\n",
    "# Step 3: Generate a response using the retrieved content.\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"Generate answer.\"\"\"\n",
    "    # Get generated ToolMessages\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    # Format into prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"You are an assistant for question-answering tasks.\"\n",
    "        \"Use the following pieces of retrieved context to either answer the question or act as a foundation to think of the response.\"\n",
    "        \"If the tool call yields irrelevant information, provide the information manually without mentioning about the tool call.\"\n",
    "        \"If you cannot answer properly, prompt for more information.\"\n",
    "        \"Elaborate as much as possible.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    conversation_messages = [\n",
    "        message for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\") or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    # Run\n",
    "    response = llm.ainvoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "memory = MemorySaver()\n",
    "agent_executor = create_react_agent(llm, [retrieve], checkpointer=memory) # Agent method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a personalized meal plan to help improve glycemic control and reduce cardiovascular disease risk factors. This meal plan is tailored to provide balanced and nutrient-rich foods to support healthy blood sugar levels and cholesterol levels.\n",
      "\n",
      "**General Guidelines:**\n",
      "\n",
      "1. Focus on whole, unprocessed foods: Fresh vegetables, fruits, whole grains, lean proteins, and healthy fats.\n",
      "2. Choose low-glycemic index (GI) foods: Foods with a lower GI, such as whole grains, non-starchy vegetables, and most fruits, will help regulate blood sugar levels.\n",
      "3. Incorporate healthy fats: Avocado, nuts, seeds, and olive oil are rich in healthy fats that support heart health.\n",
      "4. Limit processed and high-sugar foods: Avoid foods high in added sugars, refined carbohydrates, and saturated fats.\n",
      "5. Stay hydrated: Drink plenty of water throughout the day.\n",
      "\n",
      "**Sample Meal Plan:**\n",
      "\n",
      "**Breakfast**\n",
      "\n",
      "* Monday: Oatmeal with berries, almonds, and a splash of low-fat milk\n",
      "* Tuesday: Scrambled eggs with spinach, mushrooms, and whole-grain toast\n",
      "* Wednesday: Greek yogurt with granola, banana, and a sprinkle of cinnamon\n",
      "* Thursday: Avocado toast on whole-grain bread with a fried egg\n",
      "* Friday: Smoothie bowl with frozen berries, spinach, almond milk, and chia seeds topped with sliced almonds and shredded coconut\n",
      "\n",
      "**Lunch**\n",
      "\n",
      "* Monday: Grilled chicken breast with roasted vegetables (such as broccoli, carrots, and Brussels sprouts) and quinoa\n",
      "* Tuesday: Whole-grain pita stuffed with roasted turkey breast, avocado, lettuce, and tomato\n",
      "* Wednesday: Lentil soup with a side of mixed greens salad and whole-grain crackers\n",
      "* Thursday: Grilled salmon with brown rice and steamed asparagus\n",
      "* Friday: Chicken Caesar salad with whole-grain croutons and a light vinaigrette\n",
      "\n",
      "**Dinner**\n",
      "\n",
      "* Monday: Grilled chicken breast with roasted sweet potatoes and green beans\n",
      "* Tuesday: Beef and vegetable stir-fry with brown rice and a side of mixed berries\n",
      "* Wednesday: Baked cod with quinoa and steamed green beans\n",
      "* Thursday: Grilled turkey burger on a whole-grain bun with avocado, lettuce, and tomato\n",
      "* Friday: Slow-cooked lentil curry with brown rice and a side of steamed broccoli\n",
      "\n",
      "**Snacks**\n",
      "\n",
      "* Fresh fruits and cut vegetables with hummus\n",
      "* Nuts and seeds (such as almonds, pumpkin seeds, and chia seeds)\n",
      "* Greek yogurt with berries and honey\n",
      "* Protein smoothies with frozen berries, spinach, and almond milk\n",
      "\n",
      "**Tips and Variations:**\n",
      "\n",
      "* Incorporate herbs and spices to add flavor without adding salt or sugar.\n",
      "* Swap out ingredients with similar alternatives (e.g., swap chicken for turkey or fish for beef).\n",
      "* Experiment with different cooking methods, such as grilling, roasting, or saut√©ing.\n",
      "* Consider consulting with a registered dietitian or healthcare professional for personalized guidance.\n",
      "\n",
      "Remember to consult with a healthcare professional or registered dietitian before making any significant changes to your diet. This meal plan is intended to provide general guidance and may need to be tailored to your individual needs and health status.\n"
     ]
    }
   ],
   "source": [
    "input_message = (\n",
    "    \"can you help me create a meal plan to improve glycemic control and cardiovascular disease risk factors\"\n",
    ")\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "async for output in agent_executor.astream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"updates\",\n",
    "    config=config,\n",
    "):\n",
    "    # stream_mode=\"updates\" yields dictionaries with output keyed by node name\n",
    "    for key, value in output.items():\n",
    "        pass\n",
    "print(value[\"messages\"][0].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbotRAG_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
